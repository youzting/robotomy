1. 개발 환경 준비 (25.04.04)
- 필요 프로그램 설치
- 필요 패키지 설치

2. Whisper 예제 생성 (25.04.05)
- transcribe.py 소스 코드 파일 생성 후 테스트
- 사용한 음성 파일은 https://ttsmp3.com 사이트에서 생성함
- 파일의 이름에 따라 transcribe.py 내의 model.transcribe("파일 이름") 을 수정할 필요 있음
- 영어 음성 파일(audio_test_en.mp3)의 문장은 "Hello, how are you?" 이며, 결과 또한 정상적으로
📝 Transcription:
 Hello, how are you?
이와 같이 출력됨을 확인함
- 영어 음성에 이어 한글 음성(audio_test_kr.mp3)으로도 테스트 실행함. 문장을 "안녕하세요."로 작성하였고,
📝 Transcription:
 안녕하세여
이와 같이 출력됨을 확인함
- 팀원의 추가 테스트 요청에 따라 일본어 음성(audio_test_jp.mp3)으로 테스트 실행함. 문장은 "皆さん、こんばんは。いい夜ですね。"로 작성하였고,
📝 Transcription:
皆さんこんばんはいい夜ですね
이와 같이 출력됨을 확인함
- 테스트 실행 결과
간단한 문장을 텍스트로 출력하는 데 노트북 환경에서 7초 정도 소요됨
추후 소요 시간을 줄이는 방법을 모색하겠음

3. TTS 예제 생성 (25.04.06)
- speak.py 소스 코드 파일 생성 후 테스트
- 처음 사용한 TTS 모델은, "tts_models/en/ljspeech/tacotron2-DDC"이며 첫 실행 시 모델을 로드하는 데 시간이 소요됨
- tts.tts_to_file(text="Hello, how are you today?", file_path="output.wav")에서 음성으로 바꿀 텍스트는 text="문장 내용"에서 바꿀 수 있고,
파일 이름은 file_path="파일 이름"에서 바꿀 수 있음
- 영어 문장 "Hello, how are you today?" 입력 결과 output_test_en.wav 파일이 생성됨
- 초기 코드에서는 영어 모델만 사용했기에, 영어 문장만 음성 파일로 만들 수 있음
- 여러 언어를 사용하기 위해서, 다양한 언어의 TTS 모델(영어,한글,일본어,...)을 가져와서 langdetect 패키지를 설치함
- langdetect 패키지를 쓰면 문장의 언어를 감지해서 자동으로 모델을 선택할 수 있음

4. TTS 다국어 모델 테스트 (25.04.13)
- speak.py 소스 코드 교체
- 현재 TTS 라이브러리는 한국어 모델을 지원하지 않음
- 이로 인해 다국어 모델을 통해서 한국어 음성을 출력 시도함
- 사용하는 다국어 모델은 xtts_v2
- 입력한 예시용 음성 파일을 토대로 원하는 문장을 TTS 음성 파일로 만들어 냄
- 먼저, 영어를 테스트하기 위해서 audio_test_en.mp3 파일을 토대로 "Hello, how are you? Nice to meet you." 문장을 작성하였고,
output_test_en.wav 파일이 출력됨
음성 파일 실행 결과 자연스러운 영어 음성이 출력됨을 확인함
- 두 번째로, 한국어를 테스트하기 위해서 audio_test_kr.mp3 파일을 토대로, "안녕하세요, 만나서 반갑습니다. 좋은 하루 되세요." 문장을 작성하였고,
output_test_kr.wav 파일이 출력됨
음성 파일 실행 결과 자연스러운 한국어 음성이 출력됨을 확인함

5. 실시간 대화 시스템 워크 플로우 및 코드 설계 (25.04.20)
- 노트북 고장으로 인해 현재 실시간 대화 시스템 코드 직접 테스트 불가
- 실시간 대화 시스템 워크 플로우 설계
- 실시간 대화 시스템 코드 설계
- 테스트 및 보완은 04.21.(월) 노트북 수리 완료 예정일에 진행할 것임

6. TTS 테스트 후 개선 (25.04.26)
- speak.py 소스 코드 개선
- langdetect를 이용해 text의 언어를 추정함
- 추정한 언어를 기반으로 언어 별 TTS 모델을 사용함
- 영어의 경우 ljspeech/tacotron2-DDC 사용
- 한국어의 경우 TTS 라이브러리가 한국어 모델을 지원하지 않기에 다국어 모델 xtts_v2 사용
- 일본어의 경우 현재 fugashi와 MeCab 간 오류로 인해 일시적으로 개발 중지 및 차후 개선 예정

7. 실시간 대화 시스템 코드 개선 (25.04.27)
- realtime_chat.py 코드 개선
- 현재 개발은 음성 파일 입력->Whisper로 음성-텍스트 변환->정해둔 응답 생성->텍스트-음성 TTS 생성->자동 출력 까지 이루어짐
- 마이크를 이용한 음성 입력 기능 개발 완료
- 음성 감지 시 음성 녹음 시작 기능 추가
- 일정 시간 이상 무음일 시 녹음 종료 기능 추가
- 종료 키(Ctrl+C) 입력 전까지 대화 자동 반복 기능 추가
- OpenAI API키 유료 결제 필요로 ChatGPT 연결을 통한 응답 생성 기능 테스트 일시 정지

8. TTS 테스트 후 개선 (25.05.04)
- speak.py 소스 코드 개선
- 일본어 전용 모델 kokoro/tacotron2-DDC 사용
- fugashi와 MeCab간 오류 해결

9. TTS 테스트 후 개선 (25.05.11)
- speak.py 소스 코드 개선
- 중국어(간체) 전용 모델 baker/tacotron2-DDC-GST 사용
- 한국어/영어/일본어/중국어(간체) 총 4개 국어 테스트 완료

10. 실시간 대화 시스템 코드 개선 (25.05.18)
- realtime_chat.py 코드 개선
- 음성 감지 기능이 너무 민감하게 작동 하여 녹음 시작 기능을 키보드 'r'키 입력 시 녹음 시작 가능하게 변경
- realtime_chat_withGPT.py 코드 개선
- OpenAI API 키를 이용한 ChatGPT 연결 성공
- 아래는 실행할 때의 텍스트 출력 내용

📥 Whisper 모델 로딩 중...
📤 TTS 모델 로딩 중...
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
🔁 대화를 시작하려면 'r', 종료하려면 'q' 키를 누르세요.
⌨️  'r' 키를 누르면 녹음이 시작됩니다.
🎤 녹음 중... 말하세요.
✅ 녹음 완료.
🧠 음성 → 텍스트 변환 중...
C:\Users\hieto\projects\tts_venv\lib\site-packages\whisper\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead
  warnings.warn("FP16 is not supported on CPU; using FP32 instead")
📝 사용자:  한국의 가수 G-Dragon에 대해서 간단히 말해줄래?
🤖 답변: 네, G-Dragon은 대한민국의 가수이자 래퍼이자 음악 프로듀서로, K-pop 그룹인 빅뱅의 멤버이기도 합니다. 그는 자신의 독특한 음악 스타일과 창의적인 음악 작업으로  국내외에서 많은 팬들을 사로잡았으며, 한류 스타로서도 큰 인기를 얻고 있습니다. 그의 음악은 다양한 장르를 아우르며, 강렬한 퍼포먼스와 독보적인 이미지로 많은 이들에게 영감을 주고 있습니다.
 > Text splitted to sentences.
['네, G-Dragon은 대한민국의 가수이자 래퍼이자 음악 프로듀서로, K-pop 그룹인 빅뱅의 멤버이기도 합니다.', '그는 자신의 독특한 음악 스타일과 창의적인 음악 작업으로 국내 외에서 많은 팬들을 사로잡았으며, 한류 스타로서도 큰 인기를 얻고 있습니다.', '그의 음악은 다양한 장르를 아우르며, 강렬한 퍼포먼스와 독보적인 이미지로 많은 이들에게 영 감을 주고 있습니다.']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > Processing time: 160.9803490638733
 > Real-time factor: 4.888848223928478
🔊 응답 생성 완료: response.wav
🔁 대화를 시작하려면 'r', 종료하려면 'q' 키를 누르세요.
👋 종료합니다.

11. ChatGPT에 도슨트 프롬프트 적용 테스트 (25.05.25)
- realtime_chat_withGPT.py 코드 개선
- 정확한 발음의 질문이 아닐 경우, 답변의 내용이 크게 달라지는 문제 발생
- 답변 내용을 TTS로 변환할 때 시간이 많이 소요됨
- 아래는 테스트한 답변 내용

['빗살모니 토기는 신라 시대에 만들어진 토기로, 빗살 모양의 무늬가 특징입니다.', '이 토기는 주로 식기로 사용되었는데, 그 당시 사람들이 깊은 빗살 모양을 만들기 위해 얼 마나 세밀하고 정교하게 일을 했는지 상상해 보세요.', '이 토기는 신라 문화의 정교함과 미를 잘 보여주는 작품이에요.']
['통일 신라우의 전통 가옥 양식은 단층 구조로 지어진 담장을 둘러싸고, 지붕은 기와로 덮여 있습니다.', '이 가옥은 주로 나무와 돌로 건축되어 있어요.', '통일 신라우의 가옥은 자연환경과 조화를 이루며, 안뜰을 중심으로 주거 공간이 배치돼 있습니다.', '이 가옥은 우리 문화의 아름다움과 옛 전통을 엿볼 수 있는 소중한 유산이에요.']

위와 같이 답변이 정확하지 않을 경우, Whisper의 STT 기능이 효과적이지 않음
또한, 4문장 정도를 TTS로 변환하는데 30초가 넘는 시간이 소요됨

12. MBTI - ESTJ 유형에 대한 자료조사 및 정리, 시스템 프롬프트 개선 및 AI 파인 튜닝 진행 (25.05.28)
- MBTI 중 ESTJ 유형에 대한 자료조사 및 정리(자료조사 - MBTI 파일에 정리)
- 시스템 프롬프트 개선(프롬프트 디렉터리에 파일 업로드)
- 위 두 가지를 바탕으로 도슨트 AI 로봇에 ESTJ형 시스템 프롬프트를 적용 후 테스트 진행
- 현재 AI가 질문을 받았을 경우에 작품명, 제작자와 연도, 특징, 소장처에 대한 소개를 7~8 문장 내로 설명할 수 있음
- ChatGPT와 연동되었기에 정확하지 않은 답변이 발생하는 경우도 있음 -> 파인 튜닝을 통해 해결 예정

13. MBTI - ESTJ 유형의 시스템 프롬프트 개선, whisper 모델 변경, GPU 환경 사용, Whisper 및 TTS 처리 속도 개선 (25.06.08)
- ESTJ의 설명 시 목소리 특징
톤 - 낮고 단호하거나 약간 높은 중저음으로 명확하게 전달함
속도 - 보통에서 빠른 속도로 논리적인 순서에 따라 말함
억양 - 감정보다는 강조와 명확성에 초점을 맞춤, 끝맺음을 분명히 함
발음 - 정확하고 또렷함, 중간에 머뭇거리거나 "음..." 등의 감탄사를 거의 쓰지 않음

- tts 파라미터에 아래 사항 추가 시도
speed=1.1,           # 약간 빠르게
energy=1.2,          # 더 명확하게
pitch=0.9            # 약간 낮은 음성 톤
-> 시도 결과 : xtts_v2 모델이 더 이상 energy, pitch 파라미터를 사용하지 않아 오류 발생

- xtts_v2 모델은 음성 참조 파일 "speaker_wav"를 기반으로 발화 생성
-> 대안 : 음성 파일 후처리 또는 텍스트 스타일로 속도를 조절함

- 시스템 프롬프트 개선(자연스러운 설명 진행)
- 잘못된 응답 연결 방지를 위한 조건 추가
-> "작품명이 명확하지 않거나, 존재하지 않는 항목일 경우, 유사한 항목이 있으면 그에 대해 설명하세요. 유사 항목도 없을 경우 "자료가 없습니다"라고 답변하세요."

- 기존 사용 whisper 모델 : base
-> tiny 사용 결과: 응답 속도 빠름, 하지만 품질이 너무 저하됨
-> small 사용 결과: 응답 속도 보통, 품질 보통

- 현재 실행 결과
📥 Whisper 모델 로딩 중...
📤 TTS 모델 로딩 중...
 > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.
 > Using model: xtts
GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
🔁 대화를 시작하려면 'r', 종료하려면 'q' 키를 누르세요.
⌨️  'r' 키를 누르면 녹음이 시작됩니다.
🎤 녹음 중... 말하세요.
✅ 녹음 완료.
🧠 음성 → 텍스트 변환 중...
C:\Users\hieto\projects\tts_venv\lib\site-packages\whisper\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead
  warnings.warn("FP16 is not supported on CPU; using FP32 instead")
📝 사용자:  미켈란 제로의 천지 창조에 대해서 설명해줘
🤖 답변: 천지 창조는 미켈란젤로 부오나로티에 의해 제작된 조각 작품으로, 1508년에서 1512년 사이에 만들어졌습니다. 이 작품은 성경에 기반을 둔 건축 조각이며, 미켈란젤로 가 최고의 예술작품 중 하나로 꼽히는 작품 중 하나입니다. 천지 창조는 신이 아담에게 생명을 불어넣는 장면을 형상화한 것으로 유명하며, 미켈란젤로의 뛰어난 해부학적 지식과 조각 기술이 돋보입니다. 이 작품은 현재 바티칸 시티 소장품으로 전시되고 있습니다.
 > Text splitted to sentences.
['천지 창조는 미켈란젤로 부오나로티에 의해 제작된 조각 작품으로, 1508년에서 1512년 사이에 만들어졌습니다.', '이 작품은 성경에 기반을 둔 건축 조각이며, 미켈란젤로가 최고의 예술작품 중 하나로 꼽히는 작품 중 하나입니다.', '천지 창조는 신이 아담에게 생명을 불어넣는 장면을 형상화한 것으로 유명하며, 미켈란젤로의 뛰어난 해부학적 지식과  조각 기술이 돋보입니다.', '이 작품은 현재 바티칸 시티 소장품으로 전시되고 있습니다.']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
 > Processing time: 189.40400314331055
 > Real-time factor: 4.097682760312007
🔊 응답 생성 완료: response.wav
🔁 대화를 시작하려면 'r', 종료하려면 'q' 키를 누르세요.
⌨️  'r' 키를 누르면 녹음이 시작됩니다.
🎤 녹음 중... 말하세요.
✅ 녹음 완료.
🧠 음성 → 텍스트 변환 중...
📝 사용자:  고려청자에 대해서 설명해줘
🤖 답변: 고려청자는 고려시대에 제작된 도자기로, 주로 백자나 청자로 알려져 있습니다. 고려청자는 10~14세기에 많이 제작되었으며, 순백색이나 연녹색, 청록색 등의 색감을 가지고 있습니다. 주로 꽃무늬나 조각, 글씨 등이 섬세하게 그려져 있습니다. 고려청자는 주로 궁중에서 사용되었으며, 고려시대의 세련된 미를 엿볼 수 있는 작품으로 소장되어 있습니다.
 > Text splitted to sentences.
['고려청자는 고려시대에 제작된 도자기로, 주로 백자나 청자로 알려져 있습니다.', '고려청자는 10~14세기에 많이 제작되었으며, 순백색이나 연녹색, 청록색 등의 색감을 가지고 있습니다.', '주로 꽃무늬나 조각, 글씨 등이 섬세하게 그려져 있습니다.', '고려청자는 주로 궁중에서 사용되었으며, 고려시대의 세련된 미를 엿볼 수 있는 작품으로 소장되어 있습니다.']
 > Processing time: 164.82572031021118
 > Real-time factor: 4.526712750149657
🔊 응답 생성 완료: response.wav
🔁 대화를 시작하려면 'r', 종료하려면 'q' 키를 누르세요.
👋 종료합니다.

- 분석:
MBTI-ESTJ 유형의 설명 방식을 잘 따라감.
작품명, 제작자 및 연도, 특징, 소장처 설명을 잘 하고 있음.
Real-time factor가 너무 큼, 실행 시간이 오래 걸림.

- 현재 노트북 사양:
GeForce GTX 1650 with Max-Q Design

- PyTorch GPU 버전 설치
- Whisper 모델 load 시 cuda 명시
- TTS 모델 load 시 gpu=True 명시

14. TTS 처리 문제점 개선 (25.06.13)
- GPU 사용 시 4GB의 현재 기기 사양으로는 TTS(xtts_v2) 모델의 높은 요구 사양이 충족되지 않음

- 아래의 해결 방안 존재
- 해결 방안 1. xtts_v2(다국어 모델)을 한국어 전용 모델(ko/kss/tacotron2-DDC)로 변경
- 해결 방안 2. 응답 생성 -> 문장 별 분할 -> 문장마다 TTS 출력 방식 사용

- 해결 방안 2 선택 및 테스트 진행
- 마지막 문장만 출력되는 상황 발생
- for 반복문 내에 TTS 출력을 추가하여 문제점 해결

- 실시간 도슨트처럼 "한 문장씩 말하고 다음으로 넘어가는 방식" 구현 완료

15. 문제점 해결 및 보류 (25.06.14)
- 해결 방안 2를 사용해도 긴 문장의 경우 GPU cuda 메모리 부족 오류 발생
- 해결 방안 1 시도
- 최신 TTS 라이브러리는 한국어 ko/kss 모델을 지원하지 않음
- 노트북 환경에서는 CPU 사용 -> 응답 시간 오래 걸림
- GPU 환경은 차후 시도 및 해결 예정
