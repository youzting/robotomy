각 언어별로 모델을 사용하려고 했지만, 현재 최신 TTS 라이브러리는 한국어 모델을 지원하지 않음
해당 이슈로 다국어 모델을 연구하고 사용하려 함
현재 다국어 모델에 대한 한국어, 영어 테스트는 완료함

TTS는 텍스트를 음성으로 바꾸어주는 모델로 해당 프로젝트에서는 아래의 모델을 사용함
모델: tts_models/multilingual/multi-dataset/xtts_v2

장점
다국어 TTS 지원: 영어, 한국어, 일본어 등 다양한 언어 발화 가능
화자 스타일 복제: speaker_wav로 사용자의 말투나 억양 복제 가능
자연스러운 발음: 인간 발화에 가까운 억양과 발음 (언어 따라 차이 있음)
동일 모델로 다언어 지원: 언어마다 모델을 따로 받지 않아도 됨
Whisper와 연결 쉬움: Whisper의 출력 텍스트를 그대로 입력 가능

단점
모델 무게 큼: 추론 시 자원 많이 사용 (GPU가 더 효율적)
발음 오류: 긴 문장이나 외래어, 줄임말에서 어색할 수 있음
스타일 복제 품질 차이: speaker_wav의 품질이나 길이에 따라 결과 달라짐
속도: 긴 문장일수록 생성 시간이 길어짐
