import socket
import threading
import whisper
import subprocess
import soundfile as sf
import sounddevice as sd
from TTS.api import TTS
import torch
import openai
import re
import keyboard

# ğŸ“Œ OpenAI í‚¤
openai.api_key = "YOUR_OPENAI_API_KEY"

# ğŸ“Œ Whisper + TTS ëª¨ë¸ ì´ˆê¸°í™”
print("ğŸ“¥ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
whisper_model = whisper.load_model("base", device="cuda")

print("ğŸ“¤ TTS ëª¨ë¸ ë¡œë”© ì¤‘...")
tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2", gpu=True)

# ğŸ“ ê°ì • ì˜ìƒ ê²½ë¡œ
VIDEO_PATHS = {
    "happy": "happy_smooth.mp4",
    "sad": "sad_smooth.mp4",
    "angry": "angry_smooth.mp4"
}

# ğŸ”Š TTS ìŒì„± ì¬ìƒ
def speak(text, speaker_audio="audio_test_ko.wav"):
    print(f"ğŸ—£ï¸ TTS ì¶œë ¥: {text}")
    output_path = "response.wav"
    tts.tts_to_file(
        text=text,
        file_path=output_path,
        speaker_wav=speaker_audio,
        language="ko",
        speed=1.1
    )
    data, rate = sf.read(output_path)
    sd.play(data, rate)
    sd.wait()

# ğŸ¥ ê°ì • ì˜ìƒ ì¬ìƒ
def play_video(video_file):
    subprocess.Popen(["start", "", video_file], shell=True)

# ğŸ§ Whisper ìŒì„± â†’ í…ìŠ¤íŠ¸
def record_and_transcribe(duration=5):
    print("âŒ¨ï¸ 'r' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘")
    keyboard.wait('r')
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘...")
    rec = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='int16')
    sd.wait()
    sf.write("input.wav", rec, 16000)
    print("ğŸ“¤ Whisper í…ìŠ¤íŠ¸ ë³€í™˜...")
    result = whisper_model.transcribe("input.wav", language="ko")
    return result["text"].strip()

# ğŸ§  GPT ì‘ë‹µ ìƒì„±
def get_gpt_response(user_text):
    system_prompt = """ë‹¹ì‹ ì€ ESTJ ì„±í–¥ì˜ ë„ìŠ¨íŠ¸ ë¡œë´‡ì…ë‹ˆë‹¤... (ì¤‘ëµ)"""
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text}
            ],
            max_tokens=500,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print("âŒ GPT ì˜¤ë¥˜:", e)
        return "GPT ì²˜ë¦¬ ì˜¤ë¥˜ ë°œìƒ"

# âœ‚ï¸ ë¬¸ì¥ ë¶„í• 
def split_sentences(text):
    return re.split(r'(?<=[.!?])\s+', text.strip())

# ğŸ’¬ í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ìŒì„± or í´ë¼ì´ì–¸íŠ¸ë¡œ ë°›ì€ ê²ƒ)
def process_input(text):
    print(f"ğŸ“¨ ì…ë ¥: {text}")
    if text in VIDEO_PATHS:
        play_video(VIDEO_PATHS[text])
        speak(f"í˜„ì¬ ìƒíƒœëŠ” {text} ì…ë‹ˆë‹¤.")
        return

    response = get_gpt_response(text)
    print("ğŸ¤– GPT ì‘ë‹µ:", response)
    for sentence in split_sentences(response):
        speak(sentence)
        torch.cuda.empty_cache()

# ğŸ§  ì†Œì¼“ ì„œë²„ ëª¨ë“œ
def start_socket_server():
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.bind(('', 12345))
    server.listen()
    print("âœ… ì†Œì¼“ ì„œë²„ ì‹¤í–‰ ì¤‘ (port 12345)")
    while True:
        client_socket, addr = server.accept()
        print(f"ğŸ”— ì—°ê²°ë¨: {addr}")
        threading.Thread(target=handle_client, args=(client_socket,)).start()

def handle_client(sock):
    with sock:
        while True:
            msg = sock.recv(1024).decode('utf-8').strip()
            if not msg:
                break
            if msg == "exit":
                print("ğŸ‘‹ í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ìš”ì²­")
                break
            process_input(msg)

# ğŸ” ëŒ€í™” ë£¨í”„ ì‹œì‘
def main_loop():
    while True:
        print("ğŸ›ï¸ '1': ìŒì„± ì…ë ¥ | '2': ì†Œì¼“ ì„œë²„ ëª¨ë“œ | 'q': ì¢…ë£Œ")
        key = keyboard.read_event().name
        if key == '1':
            text = record_and_transcribe(duration=7)
            process_input(text)
        elif key == '2':
            start_socket_server()
        elif key == 'q':
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
            break

if __name__ == "__main__":
    main_loop()
