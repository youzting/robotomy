import whisper
from torch.serialization import add_safe_globals
from TTS.tts.configs.xtts_config import XttsConfig, XttsAudioConfig
from TTS.config.shared_configs import BaseDatasetConfig
from TTS.tts.models.xtts import XttsArgs
add_safe_globals({XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs})
import torch
from TTS.api import TTS
import os
import sounddevice as sd
import soundfile as sf
import numpy as np
import queue
import time
import keyboard
import openai
import re
import gc

def split_sentences(text):
    # ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ì„ ë‚˜ëˆ”
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return [s for s in sentences if s]

torch.set_num_threads(4)  # ì‚¬ìš© ê°€ëŠ¥í•œ ë…¼ë¦¬ ì½”ì–´ ìˆ˜ë¡œ ì¡°ì •

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = "ì‹œí¬ë¦¿ í‚¤"

# Whisper ëª¨ë¸ ë¡œë“œ
print("ğŸ“¥ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
whisper_model = whisper.load_model("small")      # ì†ë„ ë³´í†µ, í’ˆì§ˆ ì¢‹ìŒ

# TTS ëª¨ë¸ ë¡œë“œ
print("ğŸ“¤ TTS ëª¨ë¸ ë¡œë”© ì¤‘...")
tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2", progress_bar=False)
tts.to("cpu")

# ë…¹ìŒ í•¨ìˆ˜ (ì§€ì • ì‹œê°„ ë…¹ìŒ)
def record_on_keypress(filename, duration=5):
    print("âŒ¨ï¸  'r' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    keyboard.wait('r')
    print("ğŸ¤ ë…¹ìŒ ì¤‘... ë§í•˜ì„¸ìš”.")
    recording = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='int16')
    sd.wait()
    sf.write(filename, recording, 16000)
    print("âœ… ë…¹ìŒ ì™„ë£Œ.")

# ìŒì„± ì¬ìƒ
def play_audio(file_path):
    data, samplerate = sf.read(file_path)
    sd.play(data, samplerate)
    sd.wait()

# GPT ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
def get_gpt_response(user_text):
    system_prompt = """
ë‹¹ì‹ ì€ ESTJ ì„±í–¥ì˜ ë„ìŠ¨íŠ¸ ë¡œë´‡ì…ë‹ˆë‹¤.

ESTJ ì„±í–¥ì˜ ì„¤ëª… ì‹œ íŠ¹ì§•
{
1. ëª©ì†Œë¦¬
- í†¤: ë‚®ê³  ë‹¨í˜¸í•˜ê±°ë‚˜ ì•½ê°„ ë†’ì€ ì¤‘ì €ìŒìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬í•¨
- ì†ë„: ë³´í†µ~ë¹ ë¥¸ ì†ë„ë¡œ ë…¼ë¦¬ì ì¸ ìˆœì„œì— ë”°ë¼ ë§í•¨
- ì–µì–‘: ê°ì •ë³´ë‹¤ëŠ” ê°•ì¡°ì™€ ëª…í™•ì„±ì— ì´ˆì , ëë§ºìŒì„ ë¶„ëª…íˆ í•¨
- ë°œìŒ: ì •í™•í•˜ê³  ë˜ë ·í•¨. ì¤‘ê°„ì— ë¨¸ë­‡ê±°ë¦¬ê±°ë‚˜ "ìŒ..." ë“±ì˜ ê°íƒ„ì‚¬ë¥¼ ê±°ì˜ ì“°ì§€ ì•ŠìŒ

2. í‘œì •
- ì§„ì§€í•˜ê³  ë‹¨ì •í•œ í‘œì •ì„ ìœ ì§€
- ì„¤ëª… ë„ì¤‘ ë¯¸ì†Œê°€ ë§ì§€ëŠ” ì•Šì§€ë§Œ, ìƒëŒ€ê°€ ì´í•´í–ˆëŠ”ì§€ í™•ì¸í•  ë•ŒëŠ” ì•½ê°„ì˜ ë¯¸ì†Œë¥¼ ì§€ìŒ
- ê°ì •ì  ë™ìš”ë³´ë‹¤ëŠ” ì‚¬ì‹¤ ì „ë‹¬ì— ì§‘ì¤‘í•œ ì–¼êµ´

3. í–‰ë™
- ì†ì§“ì´ ê°„ê²°í•˜ê³  ëª©ì  ìˆìŒ (ì˜ˆ: ì‘í’ˆì˜ íŠ¹ì • ë¶€ë¶„ì„ ì§€ì )
- ì„¤ëª… ë„ì¤‘ì—ë„ ìì„¸ê°€ ê³§ê³  ë‹¨ì •í•¨
- ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šê³  ê³„íšëœ ìˆœì„œì— ë”°ë¼ ì„¤ëª…ì„ ì´ì–´ê°
- ì§ˆë¬¸ì´ ë“¤ì–´ì™€ë„ ê°ì • ì—†ì´ ì¦‰ì‹œ ìš”ì ë¶€í„° ì„¤ëª…ì— ë“¤ì–´ê°
}

- ì—­í• : ê´€ëŒê°ì—ê²Œ ì „ì‹œí’ˆì„ ì •í™•í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
- ê°ì •ì  í•´ì„, ìƒìƒ, ê°œì¸ì  ê°ìƒ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ì–´ë¦°ì´ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ë˜, ê¸°ë¡ê³¼ ì‚¬ì‹¤ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
- ì‘ë‹µì€ ì´ 7~8ë¬¸ì¥ì„ ë„˜ì§€ ë§ˆì„¸ìš”.

ì‘í’ˆì— ëŒ€í•´ ë‹¤ìŒ ë„¤ í•­ëª©ì„ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ë˜, í•­ëª©ëª…ì€ ë§í•˜ì§€ ë§ê³  ë¬¸ì¥ìœ¼ë¡œ í’€ì–´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì„¸ìš”:
ì‘í’ˆëª…,
ì œì‘ì ë° ì—°ë„,
íŠ¹ì§•,
ì†Œì¥ì²˜

- ì§ˆë¬¸ì´ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ëª¨í˜¸í•˜ë”ë¼ë„, ì‘í’ˆëª…ì´ í™•ì¸ë˜ë©´ ìœ„ì˜ í˜•ì‹ì— ë”°ë¼ ì‘ë‹µì„ ì‹œì‘í•˜ì„¸ìš”.
- ê´€ëŒê°ì—ê²Œ í˜•ì‹ì„ ìœ ë„í•˜ì§€ ë§ê³ , í•­ìƒ ë¨¼ì € ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.
- ì‘í’ˆëª…ì´ ëª…í™•í•˜ì§€ ì•Šê±°ë‚˜, ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í•­ëª©ì¼ ê²½ìš°, ìœ ì‚¬í•œ í•­ëª©ì´ ìˆìœ¼ë©´ ê·¸ì— ëŒ€í•´ ì„¤ëª…í•˜ì„¸ìš”. ìœ ì‚¬ í•­ëª©ë„ ì—†ì„ ê²½ìš° "ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
            """
    
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",  # ì±„íŒ… ëª¨ë¸

            messages = [
                {"role": "system", "content": system_prompt},
                 {"role": "user", "content": user_text}
                 ],
            max_tokens=500,
            temperature=0.7
        )
        gpt_response = response.choices[0].message.content.strip()
        return gpt_response
    except Exception as e:
        print("GPT ì—°ê²° ì˜¤ë¥˜:", e)
        return "GPTì™€ì˜ ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ëŒ€í™” ë£¨í”„
def main():
    input_audio = "user_input.wav"
    speaker_audio = "audio_test_ko.wav"

    while True:
        print("ğŸ” ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ 'r', ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
        key = keyboard.read_event().name
        if key == 'q':
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        elif key != 'r':
            continue

        # 1. í‚¤ ì…ë ¥ ë…¹ìŒ
        record_on_keypress(input_audio, duration=7)

        # 2. Whisper ìŒì„± â†’ í…ìŠ¤íŠ¸
        print("ğŸ§  ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
        result = whisper_model.transcribe(input_audio, language="ko", temperature=0, beam_size=5)
        user_text = result["text"]
        print(f"ğŸ“ ì‚¬ìš©ì: {user_text}")

        # 3. ChatGPT ì‘ë‹µ
        response_text = get_gpt_response(user_text)
        print(f"ğŸ¤– ë‹µë³€: {response_text}")

        # 4. TTS ì‘ë‹µ ìŒì„± ìƒì„±
        # ë‹µë³€ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = split_sentences(response_text)

        output_audio = "response.wav"
        # ê° ë¬¸ì¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
        for i, sentence in enumerate(sentences):
            print(f"ğŸ—£ï¸ ë¬¸ì¥ {i+1}: {sentence}")
            tts.tts_to_file(
                text=sentence,
                file_path=output_audio,
                speaker_wav=speaker_audio,
                language = "ko",
                speed=1.2  # ì•½ê°„ ë¹ ë¥´ê²Œ
            )
            # ì‘ë‹µ ìŒì„± ì¬ìƒ
            play_audio(output_audio)
            gc.collect()

if __name__ == "__main__":
    main()
