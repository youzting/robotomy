// realtime_chat.py ì— OpenAI APIí‚¤ë¥¼ ì´ìš©í•œ ChatGPT ë‹µë³€ ìƒì„± ê¸°ëŠ¥ ì¶”ê°€

import whisper
from torch.serialization import add_safe_globals
from TTS.tts.configs.xtts_config import XttsConfig, XttsAudioConfig
from TTS.config.shared_configs import BaseDatasetConfig
from TTS.tts.models.xtts import XttsArgs
add_safe_globals({XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs})
from TTS.api import TTS
import os
import sounddevice as sd
import soundfile as sf
import numpy as np
import queue
import time
import keyboard
import openai

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = "í‚¤ ì…ë ¥"

# Whisper ëª¨ë¸ ë¡œë“œ
print("ğŸ“¥ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
whisper_model = whisper.load_model("base")  # small, medium, large ì„ íƒ ê°€ëŠ¥

# TTS ëª¨ë¸ ë¡œë“œ
print("ğŸ“¤ TTS ëª¨ë¸ ë¡œë”© ì¤‘...")
tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2", progress_bar=True, gpu=False)

# ë…¹ìŒ í•¨ìˆ˜ (ì§€ì • ì‹œê°„ ë…¹ìŒ)
def record_on_keypress(filename, duration=5):
    print("âŒ¨ï¸  'r' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    keyboard.wait('r')
    print("ğŸ¤ ë…¹ìŒ ì¤‘... ë§í•˜ì„¸ìš”.")
    recording = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='int16')
    sd.wait()
    sf.write(filename, recording, 16000)
    print("âœ… ë…¹ìŒ ì™„ë£Œ.")

# ìŒì„± ì¬ìƒ
def play_audio(file_path):
    data, samplerate = sf.read(file_path)
    sd.play(data, samplerate)
    sd.wait()

# GPT ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
def get_gpt_response(user_text):
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",  # ì±„íŒ… ëª¨ë¸
            messages=[
                {"role": "system", "content": 
                 "ë‹¹ì‹ ì€ ë°•ë¬¼ê´€ì—ì„œ ê´€ëŒê°ì„ ì•ˆë‚´í•˜ëŠ” ë„ìŠ¨íŠ¸ ë¡œë´‡ì…ë‹ˆë‹¤."
                 "ë‹¹ì‹ ì˜ ì—­í• ì€ ë°©ë¬¸ê°ì—ê²Œ ì „ì‹œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
                 "ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”."
                 "ì „ì‹œí’ˆì˜ í•µì‹¬ ë‚´ìš©ì„ 1~2 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”."
                 "ê´€ëŒê°ì˜ í¥ë¯¸ë¥¼ ëŒ ìˆ˜ ìˆë„ë¡ í¥ë¯¸ë¡œìš´ ì¶”ê°€ ì •ë³´ë‚˜ ë’·ì´ì•¼ê¸° í•˜ë‚˜ë¥¼ í•¨ê»˜ ì†Œê°œí•˜ì„¸ìš”."
                 "ì–´ë¦°ì´ë¶€í„° ì–´ë¥¸ê¹Œì§€ ëª¨ë‘ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ì‰¬ìš´ ë§ê³¼ ì¹œê·¼í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                 "ì „ì²´ ë‹µë³€ì€ 3~4 ë¬¸ì¥ì„ ë„˜ê¸°ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”."
                 "ë„ˆë¬´ ë”±ë”±í•˜ì§€ ì•Šê³  ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ì•ˆë‚´í•˜ì„¸ìš”."
                 "ì§ˆë¬¸ì´ ì¡°ê¸ˆ ëª¨í˜¸í•˜ê±°ë‚˜ ì—†ì–´ë„, ì¹œì ˆí•˜ê²Œ ì „ì‹œì˜ í•µì‹¬ì„ ì†Œê°œí•˜ì„¸ìš”."},
                {"role": "user", "content": user_text}
            ],
            max_tokens=500,
            temperature=0.7
        )
        gpt_response = response.choices[0].message.content.strip()
        return gpt_response
    except Exception as e:
        print("GPT ì—°ê²° ì˜¤ë¥˜:", e)
        return "GPTì™€ì˜ ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ëŒ€í™” ë£¨í”„
def main():
    input_audio = "user_input.wav"
    speaker_audio = "audio_test_ko.wav"

    while True:
        print("ğŸ” ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ 'r', ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
        key = keyboard.read_event().name
        if key == 'q':
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        elif key != 'r':
            continue

        # 1. í‚¤ ì…ë ¥ ë…¹ìŒ
        record_on_keypress(input_audio, duration=7)

        # 2. Whisper ìŒì„± â†’ í…ìŠ¤íŠ¸
        print("ğŸ§  ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
        result = whisper_model.transcribe(input_audio)
        user_text = result["text"]
        print(f"ğŸ“ ì‚¬ìš©ì: {user_text}")

        # 3. ChatGPT ì‘ë‹µ
        response_text = get_gpt_response(user_text)
        print(f"ğŸ¤– ë‹µë³€: {response_text}")

        # 4. TTS ì‘ë‹µ ìŒì„± ìƒì„±
        output_audio = "response.wav"
        tts.tts_to_file(
            text=response_text,
            file_path=output_audio,
            speaker_wav=speaker_audio,
            language="ko"
        )
        print(f"ğŸ”Š ì‘ë‹µ ìƒì„± ì™„ë£Œ: {output_audio}")

        # 5. ì‘ë‹µ ìŒì„± ì¬ìƒ
        play_audio(output_audio)

if __name__ == "__main__":
    main()
