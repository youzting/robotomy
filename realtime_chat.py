// ë…¸íŠ¸ë¶ ìˆ˜ë¦¬ ì™„ë£Œ ì˜ˆì •ì¼ 25.04.21.(ì›”) ì´í›„ ì½”ë“œ í…ŒìŠ¤íŠ¸ ì˜ˆì •
// Whisper,ChatGPT, TTS ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹¤ì‹œê°„ ëŒ€í™” ì‹œìŠ¤í…œì˜ ì½”ë“œë¥¼ ì„¤ê³„í•´ ë‘ 

import whisper
from TTS.api import TTS
import os
import sounddevice as sd
import soundfile as sf

# --- STEP 1: Whisper ì„¤ì • ---
print("ğŸ“¥ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
whisper_model = whisper.load_model("base")  # small, medium, large ì„ íƒ ê°€ëŠ¥

# --- STEP 2: TTS ì„¤ì • ---
print("ğŸ“¤ TTS ëª¨ë¸ ë¡œë”© ì¤‘...")
tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2", progress_bar=True, gpu=False)

# --- STEP 3: ChatGPT ì‘ë‹µ (ì˜ˆì‹œ) ---
def mock_chatgpt_response(user_text):
    # ì‹¤ì œ ChatGPT API ì—°ê²° ëŒ€ì‹  ê°„ë‹¨íˆ ì‘ë‹µ ì˜ˆì‹œ
    return f"ë‹¹ì‹ ì´ ì´ë ‡ê²Œ ë§í–ˆì–´ìš”: '{user_text}' ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!"

# --- STEP 4: ìŒì„± ì¬ìƒ í•¨ìˆ˜ ---
def play_audio(file_path):
    data, samplerate = sf.read(file_path)
    sd.play(data, samplerate)
    sd.wait()

# --- STEP 5: ëŒ€í™” ë£¨í”„ ---
def main():
    # ì˜ˆì‹œìš© ìŒì„± íŒŒì¼ ì…ë ¥ (Whisperìš©)
    input_audio = "user_input.wav"  # ì‹¤ì œ ì‚¬ìš© ì‹œ mic ë…¹ìŒìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
    speaker_audio = "audio_test_ko.wav"  # í™”ì ìŒì„± ì˜ˆì‹œ (í•œêµ­ì–´ TTS ìŠ¤íƒ€ì¼ë§ìš©)

    # 1. Whisperë¡œ ìŒì„± â†’ í…ìŠ¤íŠ¸
    print("ğŸ™ï¸ ìŒì„± â†’ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘...")
    result = whisper_model.transcribe(input_audio)
    user_text = result["text"]
    print("ğŸ“ ì‚¬ìš©ìì˜ ë°œí™”:", user_text)

    # 2. ChatGPT ì‘ë‹µ ìƒì„±
    response_text = mock_chatgpt_response(user_text)
    print("ğŸ¤– ChatGPT ì‘ë‹µ:", response_text)

    # 3. TTSë¡œ ì‘ë‹µ ìŒì„± ìƒì„±
    output_audio = "response.wav"
    tts.tts_to_file(
        text=response_text,
        file_path=output_audio,
        speaker_wav=speaker_audio,
        language="ko"
    )
    print("ğŸ”Š ì‘ë‹µ ìŒì„± ìƒì„± ì™„ë£Œ:", output_audio)

    # 4. ìŒì„± ì¬ìƒ
    play_audio(output_audio)

if __name__ == "__main__":
    main()
